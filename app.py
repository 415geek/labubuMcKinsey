import streamlit as st
import openai
import os

# âœ… æ¨èä½¿ç”¨ openai>=1.0.0 ç‰ˆæœ¬æ–¹å¼åˆå§‹åŒ–å®¢æˆ·ç«¯
from openai import OpenAI
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

st.set_page_config(page_title="Labubu Ã— éº¦è‚¯é”¡ é¤é¥®çˆ†å“é¢„æµ‹æ¨¡å‹", layout="wide")
st.title("ğŸ½ï¸ Labubu Ã— éº¦è‚¯é”¡ é¤é¥®çˆ†å“é¢„æµ‹å¼•æ“")
st.caption("è¾“å…¥åŸå¸‚æˆ–èœå“åï¼Œå³å¯è·å¾—çˆ†å“é¢„æµ‹ + æ·±åº¦å•†ä¸šæ¨¡å‹åˆ†æ")

# ğŸ“ è¾“å…¥åŒºåŸŸ
col1, col2 = st.columns(2)
with col1:
    location = st.text_input("ğŸ“è¯·è¾“å…¥åŸå¸‚åæˆ–åœ°åŒºï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰", placeholder="å¦‚ San Francisco / å¹¿å·")
with col2:
    dish_name = st.text_input("ğŸœ ä½ æƒ³åˆ†æçš„èœå“åï¼ˆå¯é€‰ï¼‰", placeholder="å¦‚ é…¸èœé±¼ / Hot Pot")

# ğŸŒ è¾“å‡ºè¯­è¨€ & ğŸ“† æ—¶é—´ç»´åº¦
col3, col4 = st.columns(2)
with col3:
    lang = st.radio("ğŸŒ è¾“å‡ºè¯­è¨€", ["ä¸­æ–‡", "English"], horizontal=True)
with col4:
    timeframe = st.radio("ğŸ“† æ—¶é—´ç»´åº¦", ["ç›®å‰", "æœªæ¥3ä¸ªæœˆ", "æœªæ¥6ä¸ªæœˆ", "æœªæ¥1å¹´", "æœªæ¥3å¹´", "æœªæ¥5å¹´", "æœªæ¥10å¹´", "æœªæ¥ä¸€ä¸–çºª"], horizontal=False)

# ğŸ”˜ å¼€å§‹æŒ‰é’®
analyze_button = st.button("ğŸ” å¼€å§‹é¢„æµ‹/åˆ†æ")

# ğŸ’¡ è°ƒç”¨ OpenAI è¿›è¡Œçˆ†å“é¢„æµ‹
@st.cache_data(show_spinner=False)
def predict_hot_dishes(location, timeframe, lang="ä¸­æ–‡"):
    prompt = f"""
ä½ æ˜¯é¤é¥®å¸‚åœºé¡¾é—®ã€‚è¯·ç»“åˆä»¥ä¸‹ä¿¡æ¯ï¼š
- åœ°åŒºï¼š{location}
- æ—¶é—´ï¼š{timeframe}
é¢„æµ‹è¯¥åœ°åŒºæœªæ¥å¯èƒ½çˆ†ç«çš„10é“èœå“ï¼Œå¹¶åˆ—å‡ºå…¶èœåã€‚
è¾“å‡ºè¯­è¨€ä¸ºï¼š{lang}
"""
    try:
        resp = openai_client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.6,
        )
        content = resp.choices[0].message.content.strip()
        return [line.strip("\n0123456789.- ") for line in content.split("\n") if line.strip()]
    except Exception as e:
        return [f"âŒ çˆ†å“é¢„æµ‹å¤±è´¥ï¼š{e}"]

# ğŸ“Š å•†ä¸šæ¨¡å‹åˆ†ææ¨¡å—
@st.cache_data(show_spinner=False)
def analyze_dish_with_models(dish, lang="ä¸­æ–‡"):
    prompt = f"""
ä½ æ˜¯å•†ä¸šåˆ†æä¸“å®¶ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ¨¡å‹å¯¹èœå“ã€Œ{dish}ã€è¿›è¡Œå•†ä¸šåˆ†æï¼š
- SWOTåˆ†æ
- 4Pè¥é”€æ¨¡å‹
- è“æµ·æˆ˜ç•¥
- T.O.P.Väººæ•ˆæ¨¡å‹
- å…¶å®ƒå¸¸ç”¨æ¨¡å‹å¦‚ PESTã€AIDMAã€æ³¢ç‰¹äº”åŠ›ã€STP ç­‰
è¾“å‡ºè¯­è¨€ï¼š{lang}
å†…å®¹å°½é‡çœŸå®ã€ä¸“ä¸šã€æœ‰æ·±åº¦ï¼Œé€‚åˆé¤é¥®åˆ›ä¸šè€…é˜…è¯»ã€‚
"""
    try:
        resp = openai_client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5,
        )
        return resp.choices[0].message.content.strip()
    except Exception as e:
        return f"âŒ å•†ä¸šæ¨¡å‹åˆ†æå¤±è´¥ï¼š{e}"

# ğŸ¯ ä¸»æ‰§è¡Œé€»è¾‘
if analyze_button:
    if dish_name:
        st.subheader("ğŸ“Š çˆ†å“å•†ä¸šæ¨¡å‹åˆ†æ")
        with st.spinner("æ­£åœ¨ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š..."):
            st.markdown(analyze_dish_with_models(dish_name, lang))

    elif location:
        st.subheader(f"ğŸ“ˆ {location} åœ°åŒºçš„æ½œåœ¨çˆ†å“é¢„æµ‹ï¼ˆ{timeframe}ï¼‰")
        with st.spinner("AI æ­£åœ¨é¢„æµ‹æ½œåŠ›èœå“..."):
            predictions = predict_hot_dishes(location, timeframe, lang)
            for idx, item in enumerate(predictions, 1):
                with st.expander(f"{idx}. {item}"):
                    st.markdown(analyze_dish_with_models(item, lang))

    else:
        st.warning("âš ï¸ è¯·è‡³å°‘è¾“å…¥ä¸€ä¸ªåŸå¸‚æˆ–èœå“åä»¥å¼€å§‹åˆ†æã€‚")
