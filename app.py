import os
import streamlit as st
import numpy as np
from yelpapi import YelpAPI
import googlemaps
from openai import OpenAI
from pytrends.request import TrendReq
import re

# ---------------------------- ä¸­è‹±æ–‡åœ°åæ”¯æŒ ----------------------------
CITY_MAP = {
    "æ—§é‡‘å±±": "San Francisco",
    "æ¹¾åŒº": "San Francisco Bay Area",
    "æ´›æ‰çŸ¶": "Los Angeles",
    "çº½çº¦": "New York",
    "èŠåŠ å“¥": "Chicago",
    "è¥¿é›…å›¾": "Seattle",
    "æ³¢å£«é¡¿": "Boston",
    "åœ£åœ°äºšå“¥": "San Diego",
    "åœ£ä½•å¡": "San Jose",
    "å¥¥å…‹å…°": "Oakland",
    "åŠ å·": "California",
}

def is_chinese(text):
    return bool(re.search(r'[\u4e00-\u9fff]', text))

def normalize_location(user_input, openai_client=None):
    user_input = user_input.strip()
    if user_input in CITY_MAP:
        return CITY_MAP[user_input]
    if is_chinese(user_input) and openai_client:
        try:
            prompt = f"è¯·å°†ä»¥ä¸‹ä¸­æ–‡åŸå¸‚åç§°ç¿»è¯‘ä¸ºè‹±æ–‡ç”¨äºåœ°å›¾æœç´¢ï¼š{user_input}"
            resp = openai_client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role":"user","content":prompt}],
                temperature=0,
                max_tokens=20
            )
            return resp.choices[0].message.content.strip()
        except Exception as e:
            st.warning(f"ç¿»è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹è¾“å…¥ï¼š{e}")
    return user_input

# ---------------------------- API åˆå§‹åŒ– ----------------------------
def load_clients():
    yk, gk, ok = st.secrets["YELP_API_KEY"], st.secrets["GOOGLE_API_KEY"], st.secrets["OPENAI_API_KEY"]
    yelp = YelpAPI(yk)
    gmaps = googlemaps.Client(key=gk)
    client = OpenAI(api_key=ok)
    return yelp, gmaps, client

yelp_api, gmaps, openai_client = load_clients()

# ---------------------------- æ ¸å¿ƒå‡½æ•° ----------------------------
def analyze_sentiment_with_gpt(texts):
    prompt = "è¯·å°†ä¸‹é¢æ¯æ¡è¯„è®ºæŒ‰æ­£é¢(+1)ã€ä¸­æ€§(0)ã€è´Ÿé¢(-1)åˆ†ç±»ï¼Œå¹¶è¾“å‡ºå¹³å‡å€¼ï¼š\n"
    for t in texts:
        prompt += f"- {t}\n"
    resp = openai_client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    try:
        return float(resp.choices[0].message.content.strip())
    except:
        return 0.0

def fetch_yelp(location, openai_client=None):
    normalized_location = normalize_location(location, openai_client)
    st.info(f"ğŸ“ ä½¿ç”¨çš„åœ°å: {normalized_location}")
    try:
        result = yelp_api.search_query(term="restaurants", location=normalized_location, limit=10)
        return result.get('businesses', [])
    except Exception as e:
        st.error(f"âŒ Yelp API è¯·æ±‚å¤±è´¥ï¼š{e}")
        return []
def fetch_google_reviews(name, loc):
    reviews = []
    resp = gmaps.places(query=f"{name} in {loc}", type="restaurant")
    for r in resp.get('results', [])[:3]:
        det = gmaps.place(place_id=r['place_id'], fields=['reviews'])
        reviews += [rev['text'] for rev in det.get('result', {}).get('reviews', [])]
    return reviews

def fetch_trend_score(term, geo="US"):
    py = TrendReq()
    py.build_payload([term], geo=geo, timeframe='today 12-m')
    df = py.interest_over_time()
    return float(df[term].mean()) if not df.empty else 0.0

def fetch_regional_econ(loc):
    return {"income": 80000, "population": 500000}

def predict_hot_dishes(businesses, reviews_list, loc):
    econ = fetch_regional_econ(loc)
    candidates = ["éº»è¾£çƒ«","äº‘åé¢","å†°ç²‰"]
    results = []
    for texts in reviews_list:
        senti = analyze_sentiment_with_gpt(texts)
        for dish in candidates:
            trend = fetch_trend_score(dish[:4], geo=loc[:2].upper())
            score = 0.4*senti + 0.3*trend + 0.2*(econ["income"]/1e5) + 0.1*min(len(texts)/100,1)
            results.append((dish, round(score,3), round(senti,2), round(trend,2)))
    unique = {d[0]: d for d in results}
    return sorted(unique.values(), key=lambda x: x[1], reverse=True)[:3]

def swot(dish, senti, trend, econ):
    return {
        "Strengths": f"æƒ…æ„Ÿåˆ† {senti:.2f}ï¼Œè¶‹åŠ¿çƒ­åº¦ {trend:.1f}",
        "Weaknesses": "ä¾›åº”é“¾ç¨³å®šæ€§éœ€è¯„ä¼°",
        "Opportunities": f"åœ°åŒºäººå‡æ”¶å…¥ {econ['income']} å¸¦æ¥æ¶ˆè´¹æ½œåŠ›",
        "Threats": "ç«å“å¯èƒ½è·Ÿè¿›åŠ é€Ÿ"
    }

def four_p(dish):
    return {
        "Product": f"{dish} æœ¬åœ°ç°åˆ¶ç°å– + å£å‘³é€‚åº”",
        "Price": "ä¸­ç«¯å®šä»· + å¤–å–å¥—é¤ä¼˜æƒ ",
        "Place": "å ‚é£Ÿ+å¤–å–åŒæ¸ é“",
        "Promotion": "ç¤¾äº¤åª’ä½“+ç½‘çº¢å¸¦åŠ¨"
    }

def pest():
    return {
        "Politics": "é£Ÿå“å®‰å…¨ç›‘ç®¡ä¸¥æ ¼",
        "Economy": "æ¶ˆè´¹å›æš–",
        "Social": "å¥åº·è§£æš‘è¶‹åŠ¿",
        "Technology": "å¤–å–ä¸æ™ºèƒ½é¤é¥®åŠ é€Ÿ"
    }

# ---------------------------- Streamlit é¡µé¢ ----------------------------
st.title("labubu & éº¦è‚¯é”¡ é¤é¥®çˆ†å“é¢„æµ‹æ¨¡å‹")
loc = st.text_input("è¯·è¾“å…¥åŸå¸‚æˆ–é‚®ç¼–")
timeframe = st.selectbox("æ—¶é—´ç»´åº¦", ["ç›®å‰","æœªæ¥3æœˆ","åŠå¹´","1å¹´","3å¹´","5å¹´","100å¹´"])
if st.button("é¢„æµ‹çˆ†å“"):
    if not loc:
        st.error("è¯·å¡«å†™åœ°åŒº")
    else:
        data = fetch_yelp(loc, openai_client=openai_client)
        reviews = [fetch_google_reviews(b['name'], loc) for b in data]
        top = predict_hot_dishes(data, reviews, loc)
        econ = fetch_regional_econ(loc)
        st.markdown("### ğŸ”¥ çˆ†å“å»ºè®® Top3")
        for dish, score, senti, trend in top:
            if st.button(dish):
                st.subheader(f"{dish} æ·±åº¦åˆ†æ")
                st.write(f"ğŸ“ˆ ç»¼åˆè¯„åˆ†ï¼š{score}")
                st.write("#### SWOT åˆ†æ")
                for k,v in swot(dish,senti,trend,econ).items():
                    st.write(f"- **{k}**ï¼š{v}")
                st.write("#### 4P ç­–ç•¥")
                for k,v in four_p(dish).items():
                    st.write(f"- **{k}**ï¼š{v}")
                st.write("#### PEST åˆ†æ")
                for k,v in pest().items():
                    st.write(f"- **{k}**ï¼š{v}")
                st.write(f"ğŸ’¬ GPT å¹³å‡æƒ…æ„Ÿåˆ†ï¼š{senti:.2f}")
                st.write(f"ğŸ” Google è¶‹åŠ¿å¾—åˆ†ï¼š{trend:.1f}")
